{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 同じファイル名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/a06/rmori/spillover/data/1982/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1988/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1966/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1954/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1975/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1972/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1978/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1959/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1985/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1961/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1965/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1981/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1957/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1976/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1971/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1962/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1968/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1986/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1958/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1960/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1984/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1979/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1973/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1974/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1989/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1967/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1983/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1969/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1987/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1963/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1970/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1977/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1980/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1964/tone-a01.csv\n",
      "/work/a06/rmori/spillover/data/1956/tone-a01.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 検索対象ディレクトリ\n",
    "data_dir = \"/work/a06/rmori/spillover/data\"\n",
    "\n",
    "# 条件に一致するファイルパスを格納\n",
    "matching_paths = []\n",
    "\n",
    "# 再帰的にCSVファイルを探索\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if \"tone-a01\" in file:\n",
    "            full_path = os.path.join(root, file)\n",
    "            matching_paths.append(full_path)\n",
    "\n",
    "# 結果を表示\n",
    "for path in matching_paths:\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## キーワード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = \"生活保護\"\n",
    "word2 = \"尾道市\"\n",
    "word3 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# 空白（全角・半角）を削除したバージョンも用意\n",
    "def remove_spaces(text):\n",
    "    return re.sub(r'[\\s\\u3000]', '', text)  # \\s: 半角空白、\\u3000: 全角空白\n",
    "\n",
    "# 検索対象ディレクトリ\n",
    "data_dir = \"/work/a06/rmori/spillover/data\"\n",
    "\n",
    "# 条件に一致するファイルパスを格納\n",
    "matching_paths = []\n",
    "\n",
    "# 再帰的にCSVファイルを探索\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            full_path = os.path.join(root, file)\n",
    "            try:\n",
    "                with open(full_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    stripped = remove_spaces(content)\n",
    "                    if (word1 in stripped) and (word2 in stripped) and (word3 in stripped):\n",
    "                        matching_paths.append(full_path)\n",
    "            except UnicodeDecodeError:\n",
    "                try:\n",
    "                    with open(full_path, 'r', encoding='shift_jis') as f:\n",
    "                        content = f.read()\n",
    "                        stripped = remove_spaces(content)\n",
    "                        if (word1 in stripped) and (word2 in stripped) and (word3 in stripped):\n",
    "                            matching_paths.append(full_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ 読込失敗: {full_path} ({e})\")\n",
    "\n",
    "# 結果を表示\n",
    "for path in matching_paths:\n",
    "    print(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 対象とするキーワード（列名候補）\n",
    "keywords = [\"耕地面積\", \"製造業出荷額\", \"製造業事業所\", \"商店数\"]  # 必要に応じて増やす\n",
    "\n",
    "# 合併した旧市町村\n",
    "merged_towns = [\n",
    "    \"戸坂村\", \"中山村\", \"井口村\", \"沼田町\", \"安佐町\", \"可部町\", \"祇園町\", \"安古市町\", \"佐東町\",\n",
    "    \"高陽町\", \"瀬野川町\", \"白木町\", \"熊野跡村\", \"安芸町\", \"矢野町\", \"船越町\", \"五日市\"\n",
    "]\n",
    "\n",
    "# 空白除去用関数\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    空白、全角スペース、改行などをすべて削除して比較用文字列を返す\n",
    "    \"\"\"\n",
    "    return re.sub(r'[\\s\\u3000\\r\\n]+', '', str(text))\n",
    "\n",
    "# 各項目ごとに結果を記録\n",
    "results_by_keyword = {kw: [] for kw in keywords}\n",
    "\n",
    "for path in sorted(matching_paths):\n",
    "    match = re.search(r\"(\\d{4})\", path)\n",
    "    if not match:\n",
    "        continue\n",
    "    year = int(match.group(1))\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(path, header=None, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(path, header=None, encoding='shift_jis', errors='ignore')\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 読込失敗: {path} ({e})\")\n",
    "        continue\n",
    "\n",
    "    # 広島市の行番号を探す\n",
    "    hiroshima_row = None\n",
    "    for r in range(df.shape[0]):\n",
    "        for c in range(df.shape[1]):\n",
    "            val = df.iat[r, c]\n",
    "            if pd.isna(val):\n",
    "                continue\n",
    "            if \"広島市\" in normalize_text(val):\n",
    "                hiroshima_row = r\n",
    "                break\n",
    "        if hiroshima_row is not None:\n",
    "            break\n",
    "    if hiroshima_row is None:\n",
    "        print(f\"⚠️ 広島市が見つからない: {path}\")\n",
    "        continue\n",
    "\n",
    "    # 各キーワードに対して処理\n",
    "    for keyword in keywords:\n",
    "        # 広島市より上で最後に見つかった該当列を探す\n",
    "        keyword_col = None\n",
    "        for r in range(hiroshima_row):\n",
    "            for c in range(df.shape[1]):\n",
    "                val = df.iat[r, c]\n",
    "                if pd.isna(val):\n",
    "                    continue\n",
    "                if keyword in normalize_text(val):\n",
    "                    keyword_col = c  # 最後のものを保持\n",
    "        if keyword_col is None:\n",
    "            print(f\"⚠️ {keyword} が見つからない: {path}\")\n",
    "            continue\n",
    "\n",
    "        # 広島市の値を取得\n",
    "        hiroshima_val = pd.to_numeric(df.iat[hiroshima_row, keyword_col], errors='coerce')\n",
    "        if pd.isna(hiroshima_val):\n",
    "            hiroshima_val = 0\n",
    "\n",
    "        # 合併旧市町村の値を加算\n",
    "        for r in range(df.shape[0]):\n",
    "            found = False\n",
    "            for c in range(df.shape[1]):\n",
    "                val = df.iat[r, c]\n",
    "                if pd.isna(val):\n",
    "                    continue\n",
    "                if any(town in normalize_text(val) for town in merged_towns):\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                add_val = pd.to_numeric(df.iat[r, keyword_col], errors='coerce')\n",
    "                if not pd.isna(add_val):\n",
    "                    hiroshima_val += add_val\n",
    "\n",
    "        results_by_keyword[keyword].append((year, hiroshima_val))\n",
    "\n",
    "# ✅ 出力：DataFrame化して表示\n",
    "for keyword, data in results_by_keyword.items():\n",
    "    df_result = pd.DataFrame(data, columns=[\"year\", keyword])\n",
    "    df_result.set_index(\"year\", inplace=True)\n",
    "    print(f\"\\n📊 {keyword}（広島市＋旧市町村）:\")\n",
    "    print(df_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "river",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
